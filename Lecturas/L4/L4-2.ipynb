{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "The article presented by  Xu W., Liu X., and Gong Y presents a novel document clustering method, based on Non-Negative Matric Factorization. This factorizacion method assumes the existance of a k-dimension semantic space, where each axis represents a topic. \n",
    "\n",
    "# The algorithm\n",
    "First of all the authors construct a dictionary $\\mathcal{W} = \\{f1,f2...fm\\}$, dictionary built after word-stemming and stop-word removal.\n",
    "After that, one build the Matrix $X$, where every column is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X_i &= [x_{1i},x_{2i},...,x_{mi}]^T\\\\\n",
    "x_{ji}&= t_{ji} \\cdot log(\\frac{n}{idf_j})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Basically, every component of the matrix $X$ is a term frequency times a logarithmic inverse dictionary frequency (algorithm we saw on this week lecture 1). After that, one factorizes matrix such that $X\\approx UV^T$ where $U$ is a non-negative $m\\times k$ and $V^T$ is a non-negative $k\\times n$ matrix (which are obtained by minimizing the following cost function):\n",
    "$$\n",
    "J = \\frac{1}{2} || X - UV^T||\n",
    "$$\n",
    "\n",
    "# Relation to SysRec\n",
    "With funkSVD we saw that SVD proved to be quite benefittial for collaborative filtering using latent-factor spaces, but in a natural manner, SVD factorization uses negative values, while ratings do not. On the other hand, NNF (Non-Negative Factorization) as it's name implies, factorizes without having to use negative values, becoming more \"intuitive\" for sysrecs.\n",
    "\n",
    "There's also a similarity to SVD in the idea that one can give to the $U$ and $V$ matrices, $U$ becoming a word-topic relation matrix, while $V$ becomes a topic-document relation matrix. Clearly for sysrec the importance lies on the $V$ matrix. This matrix allows us to take non-structured data into a vectorial semantic space. The only thing we now need to create a recomendation is a $u \\times k$ $P$ matrix that represents user interest in topic k.\n",
    "\n",
    " "
   ]
  }
 ]
}